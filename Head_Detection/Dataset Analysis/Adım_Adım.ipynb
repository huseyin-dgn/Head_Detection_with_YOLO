{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5147c6fe",
   "metadata": {},
   "source": [
    "## 1.Adım ) Test - Train olarak verileri ayırmak.Amacımız overfitting önlemek amacıyla Val.txt'leri kullanmak.Diğer tarafdan da .txt dosyalarının farklı fotoğraflardan oluşmadığını kontrol etmek için bu aşamayı yapıyoruz. (check_splits.py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a92ebf6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Part A \n",
      "train: 1100 | val: 400 | test: 500\n",
      "train ∩ val: 0\n",
      "train ∩ test: 0\n",
      "val ∩ test: 0\n",
      "union(train,val,test): 2000\n",
      " Part B \n",
      "train: 1443 | val: 462 | test: 500\n",
      "train ∩ val: 0\n",
      "train ∩ test: 0\n",
      "val ∩ test: 0\n",
      "union(train,val,test): 2405\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "def read_ids(txt_path: Path) -> set[str]:\n",
    "    ids = set()\n",
    "    if not txt_path.exists():\n",
    "        raise FileNotFoundError(f\"Bulunamadı: {txt_path}\")\n",
    "    for line in txt_path.read_text(encoding=\"utf-8\", errors=\"ignore\").splitlines():\n",
    "        s = line.strip()\n",
    "        if not s:\n",
    "            continue\n",
    "        s = s.replace(\".jpg\", \"\").replace(\".png\", \"\").replace(\".jpeg\", \"\")\n",
    "        ids.add(s)\n",
    "    return ids\n",
    "\n",
    "def report_intersection(a_name: str, a: set[str], b_name: str, b: set[str], limit=30):\n",
    "    inter = sorted(a & b)\n",
    "    print(f\"{a_name} ∩ {b_name}: {len(inter)}\")\n",
    "    if inter:\n",
    "        print(\"  Örnek çakışan ID'ler:\", inter[:limit])\n",
    "\n",
    "def check_one_split(split_dir: Path, tag: str):\n",
    "    print(f\" {tag} \")\n",
    "    train = read_ids(split_dir / \"train.txt\")\n",
    "    val   = read_ids(split_dir / \"val.txt\")\n",
    "    test  = read_ids(split_dir / \"test.txt\")\n",
    "\n",
    "    print(f\"train: {len(train)} | val: {len(val)} | test: {len(test)}\")\n",
    "\n",
    "    report_intersection(\"train\", train, \"val\", val)\n",
    "    report_intersection(\"train\", train, \"test\", test)\n",
    "    report_intersection(\"val\", val, \"test\", test)\n",
    "\n",
    "    union = train | val | test\n",
    "    print(f\"union(train,val,test): {len(union)}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    PART_A_SPLIT_DIR = Path(r\"C:\\Users\\hdgn5\\OneDrive\\Masaüstü\\Head Detection\\Datasets\\SCUT_HEAD_Part_A\\ImageSets\\Main\")\n",
    "    PART_B_SPLIT_DIR = Path(r\"C:\\Users\\hdgn5\\OneDrive\\Masaüstü\\Head Detection\\Datasets\\SCUT_HEAD_Part_B\\ImageSets\\Main\")\n",
    "\n",
    "    check_one_split(PART_A_SPLIT_DIR, \"Part A\")\n",
    "    check_one_split(PART_B_SPLIT_DIR, \"Part B\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a323bda5",
   "metadata": {},
   "source": [
    "### Veri Seti Bölünmelerinin Doğrulanması\n",
    "\n",
    "Eğitim sürecine başlamadan önce, veri sızıntısını (data leakage) önlemek amacıyla veri setindeki **eğitim (train)**, **doğrulama (validation)** ve **test** bölünmeleri kontrol edilmiştir.  \n",
    "SCUT-HEAD veri setinin hem **Part A** hem de **Part B** bölümleri için tanımlı olan `train`, `val` ve `test` listeleri arasında herhangi bir kesişim olup olmadığı incelenmiştir.\n",
    "\n",
    "Yapılan kontroller sonucunda:\n",
    "- Eğitim, doğrulama ve test kümeleri arasında **herhangi bir örtüşme olmadığı**,\n",
    "- Her bir görüntünün **yalnızca tek bir kümeye ait olduğu**,\n",
    "- Üç kümenin birleşiminin, ilgili bölümdeki tüm görüntüleri kapsadığı\n",
    "\n",
    "doğrulanmıştır.\n",
    "\n",
    "Bu doğrulama, deneysel sonuçların istatistiksel olarak geçerli olmasını ve test aşamasında elde edilen performansın ezberlemeye değil, gerçek genelleme yeteneğine dayandığını garanti etmektedir.\n",
    "*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a85e85c",
   "metadata": {},
   "source": [
    "----------\n",
    "----------\n",
    "----------\n",
    "----------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6803283b",
   "metadata": {},
   "source": [
    "## Adım 2 — YOLO veri setini oluşturma (Train + Val + Test) — `build_scut_yolo.py`\n",
    "\n",
    "Bu adımda amaç, SCUT-HEAD veri setinin **Part A** ve **Part B** bölümlerini kullanarak YOLO formatında **train**, **validation (val)** ve **test** klasörlerini **tek bir akışta** oluşturmaktır.  \n",
    "Bu süreçte hem **görüntüler** hem de **etiketler (labels)** split listelerine göre doğru klasörlere yerleştirilir. İşlemin tek seferde yapılması, dosya eşleşme hatalarını (image–label mismatch) ve veri sızıntısı (data leakage) riskini azaltır.\n",
    "\n",
    "### 2.1 Hedef klasör yapısını oluştur\n",
    "Çıktı dizininde aşağıdaki klasörleri oluştur:\n",
    "\n",
    "- `scut_head_yolo/images/train/`\n",
    "- `scut_head_yolo/images/val/`\n",
    "- `scut_head_yolo/images/test/`\n",
    "- `scut_head_yolo/labels/train/`\n",
    "- `scut_head_yolo/labels/val/`\n",
    "- `scut_head_yolo/labels/test/`\n",
    "\n",
    "> Not: Ham dataset klasörlerine (SCUT_HEAD_Part_A / SCUT_HEAD_Part_B) **dokunmuyoruz**; bu klasörler **raw** olarak kalır.\n",
    "\n",
    "### 2.2 Split listelerini kaynak al\n",
    "Aşağıdaki split dosyaları **ground-truth** (referans bölünme) kabul edilir:\n",
    "\n",
    "**Part A**\n",
    "- `ImageSets/Main/train.txt`\n",
    "- `ImageSets/Main/val.txt`\n",
    "- `ImageSets/Main/test.txt`\n",
    "\n",
    "**Part B**\n",
    "- `ImageSets/Main/train.txt`\n",
    "- `ImageSets/Main/val.txt`\n",
    "- `ImageSets/Main/test.txt`\n",
    "\n",
    "Bu dosyalardaki her satır, ilgili split’e girecek görselin **ID** bilgisidir (ör. `PartB_00042`).\n",
    "\n",
    "### 2.3 Her split için uygulanacak işlem (train / val / test)\n",
    "Her split için (train, val, test) Part A ve Part B listeleri ayrı ayrı okunur ve aynı mantık uygulanır:\n",
    "\n",
    "1. **Görsel dosyasını bul**\n",
    "   - `JPEGImages/<ID>.jpg` (veya `.png/.jpeg`)\n",
    "\n",
    "2. **XML anotasyonunu bul**\n",
    "   - `Annotations/<ID>.xml`\n",
    "\n",
    "3. **XML → YOLO label dönüşümü yap**\n",
    "   - XML içindeki her `object` için bbox koordinatlarını al:\n",
    "     - `(xmin, ymin, xmax, ymax)`\n",
    "   - Görsel boyutunu XML’den oku:\n",
    "     - `width`, `height`\n",
    "   - YOLO formatına çevir (normalize):\n",
    "     - `x_center = ((xmin + xmax) / 2) / width`\n",
    "     - `y_center = ((ymin + ymax) / 2) / height`\n",
    "     - `w = (xmax - xmin) / width`\n",
    "     - `h = (ymax - ymin) / height`\n",
    "   - Sınıf tek olduğu için `class_id = 0` kullanılır (projede **head** olarak yorumlanır).\n",
    "\n",
    "4. **Çıktıları doğru split klasörüne yaz**\n",
    "   - Görseli kopyala: `scut_head_yolo/images/<split>/<ID>.<ext>`\n",
    "   - Label dosyasını yaz: `scut_head_yolo/labels/<split>/<ID>.txt`\n",
    "\n",
    "### 2.4 Bu adımın sonunda yapılacak kontroller (zorunlu)\n",
    "Veri seti üretildikten sonra aşağıdaki kontroller yapılacaktır:\n",
    "\n",
    "- **Dosya sayıları**\n",
    "  - `images/train/` beklenen: `A_train (1100) + B_train (1443) = 2543`\n",
    "  - `images/val/` beklenen: `A_val (400) + B_val (462) = 862`\n",
    "  - `images/test/` beklenen: `A_test (500) + B_test (500) = 1000`\n",
    "  - `labels/<split>/` dosya sayıları, ilgili `images/<split>/` ile **uyumlu** olmalıdır (negatif örnekler için boş `.txt` dosyaları üretilebilir).\n",
    "\n",
    "- **Leakage (kesişim) kontrolü**\n",
    "  - `train ∩ val = ∅`\n",
    "  - `train ∩ test = ∅`\n",
    "  - `val ∩ test = ∅`\n",
    "\n",
    "- **Görsel doğrulama**\n",
    "  - Her split’ten rastgele birkaç görsel seçilerek bbox çizdirilir ve görsel–label eşleşmesi gözle kontrol edilir.\n",
    "\n",
    "Bu kontroller geçmeden eğitim (fine-tuning) adımına geçilmeyecektir.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8a77a0d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== SPLIT: TRAIN ===\n",
      "Beklenen ID sayısı: 2543\n",
      "İşlenen ID sayısı: 2543\n",
      "images/train: 2543\n",
      "labels/train: 2543\n",
      "Label üretim hatası: 0\n",
      "\n",
      "=== SPLIT: VAL ===\n",
      "Beklenen ID sayısı: 862\n",
      "İşlenen ID sayısı: 862\n",
      "images/val: 862\n",
      "labels/val: 862\n",
      "Label üretim hatası: 0\n",
      "\n",
      "=== SPLIT: TEST ===\n",
      "Beklenen ID sayısı: 1000\n",
      "İşlenen ID sayısı: 1000\n",
      "images/test: 1000\n",
      "labels/test: 1000\n",
      "Label üretim hatası: 0\n",
      "\n",
      "=== OUTPUT LEAK CHECK ===\n",
      "train ∩ val : 0\n",
      "train ∩ test: 0\n",
      "val ∩ test  : 0\n",
      "\n",
      "Bitti. Çıktı klasörü: C:\\Users\\hdgn5\\OneDrive\\Masaüstü\\Head Detection\\scut_head_yolo\n"
     ]
    }
   ],
   "source": [
    "import shutil\n",
    "import xml.etree.ElementTree as ET\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "\n",
    "PART_A_ROOT = Path(r\"C:\\Users\\hdgn5\\OneDrive\\Masaüstü\\Head Detection\\Datasets\\SCUT_HEAD_Part_A\")\n",
    "PART_B_ROOT = Path(r\"C:\\Users\\hdgn5\\OneDrive\\Masaüstü\\Head Detection\\Datasets\\SCUT_HEAD_Part_B\")\n",
    "OUT_ROOT = Path(r\"C:\\Users\\hdgn5\\OneDrive\\Masaüstü\\Head Detection\\scut_head_yolo\")\n",
    "\n",
    "IMG_DIR = \"JPEGImages\"\n",
    "ANN_DIR = \"Annotations\"\n",
    "SPLIT_DIR = Path(\"ImageSets\") / \"Main\"\n",
    "\n",
    "XML_LABEL_NAME = \"person\"\n",
    "CLASS_ID = 0\n",
    "IMG_EXTS = [\".jpg\", \".jpeg\", \".png\", \".JPG\", \".JPEG\", \".PNG\"]\n",
    "\n",
    "def ensure_dir(p: Path):\n",
    "    p.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "def read_ids(txt_path: Path) -> list[str]:\n",
    "    if not txt_path.exists():\n",
    "        raise FileNotFoundError(f\"Split dosyası bulunamadı: {txt_path}\")\n",
    "    ids = []\n",
    "    for line in txt_path.read_text(encoding=\"utf-8\", errors=\"ignore\").splitlines():\n",
    "        s = line.strip()\n",
    "        if not s:\n",
    "            continue\n",
    "        s = s.replace(\".jpg\", \"\").replace(\".jpeg\", \"\").replace(\".png\", \"\")\n",
    "        ids.append(s)\n",
    "    return ids\n",
    "\n",
    "def find_img_path(root: Path, image_id: str) -> Path:\n",
    "    base = root / IMG_DIR\n",
    "    for ext in IMG_EXTS:\n",
    "        p = base / f\"{image_id}{ext}\"\n",
    "        if p.exists():\n",
    "            return p\n",
    "    raise FileNotFoundError(f\"Görsel bulunamadı: {base} | id={image_id}\")\n",
    "\n",
    "def find_xml_path(root: Path, image_id: str) -> Path:\n",
    "    p = root / ANN_DIR / f\"{image_id}.xml\"\n",
    "    if not p.exists():\n",
    "        raise FileNotFoundError(f\"XML bulunamadı: {p}\")\n",
    "    return p\n",
    "\n",
    "def get_image_size(img_path: Path) -> tuple[int, int]:\n",
    "    with Image.open(img_path) as im:\n",
    "        w, h = im.size\n",
    "    return int(w), int(h)\n",
    "\n",
    "def safe_float(text: str, default: float = 0.0) -> float:\n",
    "    try:\n",
    "        return float(text)\n",
    "    except Exception:\n",
    "        return default\n",
    "\n",
    "def voc_to_yolo_lines(xml_path: Path, img_path: Path) -> list[str]:\n",
    "    tree = ET.parse(xml_path)\n",
    "    root = tree.getroot()\n",
    "\n",
    "    w_img = h_img = 0.0\n",
    "    size = root.find(\"size\")\n",
    "    if size is not None:\n",
    "        w_img = safe_float((size.findtext(\"width\") or \"0\"), 0.0)\n",
    "        h_img = safe_float((size.findtext(\"height\") or \"0\"), 0.0)\n",
    "\n",
    "    if w_img <= 0 or h_img <= 0:\n",
    "        w, h = get_image_size(img_path)\n",
    "        w_img, h_img = float(w), float(h)\n",
    "\n",
    "    lines = []\n",
    "    for obj in root.findall(\"object\"):\n",
    "        name = (obj.findtext(\"name\") or \"\").strip()\n",
    "        if name != XML_LABEL_NAME:\n",
    "            continue\n",
    "\n",
    "        bb = obj.find(\"bndbox\")\n",
    "        if bb is None:\n",
    "            continue\n",
    "\n",
    "        xmin = safe_float(bb.findtext(\"xmin\") or \"0\")\n",
    "        ymin = safe_float(bb.findtext(\"ymin\") or \"0\")\n",
    "        xmax = safe_float(bb.findtext(\"xmax\") or \"0\")\n",
    "        ymax = safe_float(bb.findtext(\"ymax\") or \"0\")\n",
    "\n",
    "        if xmax < xmin:\n",
    "            xmin, xmax = xmax, xmin\n",
    "        if ymax < ymin:\n",
    "            ymin, ymax = ymax, ymin\n",
    "\n",
    "        xmin = max(0.0, min(xmin, w_img - 1))\n",
    "        xmax = max(0.0, min(xmax, w_img - 1))\n",
    "        ymin = max(0.0, min(ymin, h_img - 1))\n",
    "        ymax = max(0.0, min(ymax, h_img - 1))\n",
    "\n",
    "        bw = xmax - xmin\n",
    "        bh = ymax - ymin\n",
    "        if bw <= 0 or bh <= 0:\n",
    "            continue\n",
    "\n",
    "        cx = (xmin + xmax) / 2.0 / w_img\n",
    "        cy = (ymin + ymax) / 2.0 / h_img\n",
    "        bw_n = bw / w_img\n",
    "        bh_n = bh / h_img\n",
    "\n",
    "        cx = min(max(cx, 0.0), 1.0)\n",
    "        cy = min(max(cy, 0.0), 1.0)\n",
    "        bw_n = min(max(bw_n, 0.0), 1.0)\n",
    "        bh_n = min(max(bh_n, 0.0), 1.0)\n",
    "\n",
    "        lines.append(f\"{CLASS_ID} {cx:.6f} {cy:.6f} {bw_n:.6f} {bh_n:.6f}\")\n",
    "\n",
    "    return lines\n",
    "\n",
    "def build_split(split_name: str, ids_a: list[str], ids_b: list[str]):\n",
    "    img_out = OUT_ROOT / \"images\" / split_name\n",
    "    lbl_out = OUT_ROOT / \"labels\" / split_name\n",
    "    ensure_dir(img_out)\n",
    "    ensure_dir(lbl_out)\n",
    "\n",
    "    missing = []\n",
    "    written = 0\n",
    "\n",
    "    def process_one(root: Path, image_id: str):\n",
    "        nonlocal written\n",
    "        img_src = find_img_path(root, image_id)\n",
    "        xml_src = find_xml_path(root, image_id)\n",
    "\n",
    "        img_dst = img_out / img_src.name\n",
    "        shutil.copy2(img_src, img_dst)\n",
    "\n",
    "        lbl_dst = lbl_out / f\"{image_id}.txt\"\n",
    "        try:\n",
    "            yolo_lines = voc_to_yolo_lines(xml_src, img_src)\n",
    "            lbl_dst.write_text(\"\\n\".join(yolo_lines) + (\"\\n\" if yolo_lines else \"\"), encoding=\"utf-8\")\n",
    "        except Exception as e:\n",
    "            lbl_dst.write_text(\"\", encoding=\"utf-8\")\n",
    "            missing.append((image_id, str(e)))\n",
    "        written += 1\n",
    "\n",
    "    for image_id in ids_a:\n",
    "        process_one(PART_A_ROOT, image_id)\n",
    "    for image_id in ids_b:\n",
    "        process_one(PART_B_ROOT, image_id)\n",
    "\n",
    "    img_count = len(list(img_out.glob(\"*.*\")))\n",
    "    lbl_count = len(list(lbl_out.glob(\"*.txt\")))\n",
    "\n",
    "    print(f\"\\n=== SPLIT: {split_name.upper()} ===\")\n",
    "    print(f\"Beklenen ID sayısı: {len(ids_a) + len(ids_b)}\")\n",
    "    print(f\"İşlenen ID sayısı: {written}\")\n",
    "    print(f\"images/{split_name}: {img_count}\")\n",
    "    print(f\"labels/{split_name}: {lbl_count}\")\n",
    "    print(f\"Label üretim hatası: {len(missing)}\")\n",
    "\n",
    "    if missing:\n",
    "        print(\"İlk 10 hata örneği:\")\n",
    "        for mid, msg in missing[:10]:\n",
    "            print(f\"- {mid}: {msg}\")\n",
    "\n",
    "def main():\n",
    "    a_splits = PART_A_ROOT / SPLIT_DIR\n",
    "    b_splits = PART_B_ROOT / SPLIT_DIR\n",
    "\n",
    "    build_split(\"train\", read_ids(a_splits / \"train.txt\"), read_ids(b_splits / \"train.txt\"))\n",
    "    build_split(\"val\", read_ids(a_splits / \"val.txt\"), read_ids(b_splits / \"val.txt\"))\n",
    "    build_split(\"test\", read_ids(a_splits / \"test.txt\"), read_ids(b_splits / \"test.txt\"))\n",
    "\n",
    "    train_names = set(p.stem for p in (OUT_ROOT / \"images\" / \"train\").glob(\"*.*\"))\n",
    "    val_names = set(p.stem for p in (OUT_ROOT / \"images\" / \"val\").glob(\"*.*\"))\n",
    "    test_names = set(p.stem for p in (OUT_ROOT / \"images\" / \"test\").glob(\"*.*\"))\n",
    "\n",
    "    print(\"\\n=== OUTPUT LEAK CHECK ===\")\n",
    "    print(\"train ∩ val :\", len(train_names & val_names))\n",
    "    print(\"train ∩ test:\", len(train_names & test_names))\n",
    "    print(\"val ∩ test  :\", len(val_names & test_names))\n",
    "    print(\"\\nBitti. Çıktı klasörü:\", OUT_ROOT)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abcfbc1c",
   "metadata": {},
   "source": [
    "---\n",
    "----\n",
    "----\n",
    "----\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67dd7a3d",
   "metadata": {},
   "source": [
    "## Adım 3 — Split Oranlarını Yeniden Düzenleme (Train’i Güçlendirme) -- rebalance_splits.py\n",
    "\n",
    "Bu adımın amacı, resmi (train/val/test) bölünmeler üzerinden oluşturduğumuz YOLO veri setinde **eğitim (train) örnek sayısını artırmak** ve aynı zamanda **doğrulama (val)** ile **test** kümelerini daha yönetilebilir boyutlara indirerek modelin öğrenmesini kolaylaştırmaktır.\n",
    "\n",
    "Mevcut durumda test kümesi (1000 görüntü) toplam veri içinde yüksek bir paya sahiptir. Bu durum, değerlendirme güvenilirliğini artırsa da, **eğitim için kullanılabilecek veri miktarını azaltarak** model performansını sınırlayabilir. Bu nedenle, test ve validation kümelerindeki örnek sayısını hedeflediğimiz seviyelere çekip, geri kalan örnekleri train’e ekleyerek **modelin daha fazla örnek görmesini** ve **daha iyi öğrenmesini** hedefliyoruz.\n",
    "\n",
    "Bu düzenleme yapılırken temel prensipler şunlardır:\n",
    "- Train kümesi büyüt_toggle edilerek öğrenme kapasitesi artırılır.\n",
    "- Val kümesi, eğitim sırasında model seçimi ve overfitting kontrolü için yeterli büyüklükte tutulur.\n",
    "- Test kümesi, nihai performans raporlaması için makul bir boyutta tutulur.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ac2dae2",
   "metadata": {},
   "source": [
    "#### Önemli: her taşıma image + label birlikte yapılacak."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8d21f1c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: images=3355 labels=3355\n",
      "val: images=350 labels=350\n",
      "test: images=700 labels=700\n",
      "leak check train∩val: 0\n",
      "leak check train∩test: 0\n",
      "leak check val∩test: 0\n",
      "Bitti: C:\\Users\\hdgn5\\OneDrive\\Masaüstü\\Head Detection\\scut_head_yolo_rebalanced\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "\n",
    "SRC = Path(r\"C:\\Users\\hdgn5\\OneDrive\\Masaüstü\\Head Detection\\scut_head_yolo\")\n",
    "DST = Path(r\"C:\\Users\\hdgn5\\OneDrive\\Masaüstü\\Head Detection\\scut_head_yolo_rebalanced\")\n",
    "\n",
    "TARGET_VAL = 350\n",
    "TARGET_TEST = 700\n",
    "SEED = 42\n",
    "\n",
    "def ensure(p: Path):\n",
    "    p.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "def copy_tree():\n",
    "    for split in [\"train\", \"val\", \"test\"]:\n",
    "        ensure(DST / \"images\" / split)\n",
    "        ensure(DST / \"labels\" / split)\n",
    "\n",
    "    for split in [\"train\", \"val\", \"test\"]:\n",
    "        for p in (SRC / \"images\" / split).glob(\"*.*\"):\n",
    "            shutil.copy2(p, DST / \"images\" / split / p.name)\n",
    "        for p in (SRC / \"labels\" / split).glob(\"*.txt\"):\n",
    "            shutil.copy2(p, DST / \"labels\" / split / p.name)\n",
    "\n",
    "def list_stems(img_dir: Path):\n",
    "    return sorted([p.stem for p in img_dir.glob(\"*.*\") if p.is_file()])\n",
    "\n",
    "def move_pair(stem: str, from_split: str, to_split: str):\n",
    "    img_from = DST / \"images\" / from_split\n",
    "    lbl_from = DST / \"labels\" / from_split\n",
    "    img_to = DST / \"images\" / to_split\n",
    "    lbl_to = DST / \"labels\" / to_split\n",
    "\n",
    "    img_src = None\n",
    "    for p in img_from.glob(stem + \".*\"):\n",
    "        img_src = p\n",
    "        break\n",
    "    if img_src is None:\n",
    "        raise FileNotFoundError(f\"Image yok: {from_split}/{stem}\")\n",
    "\n",
    "    lbl_src = lbl_from / f\"{stem}.txt\"\n",
    "    if not lbl_src.exists():\n",
    "        raise FileNotFoundError(f\"Label yok: {from_split}/{stem}.txt\")\n",
    "\n",
    "    shutil.move(str(img_src), str(img_to / img_src.name))\n",
    "    shutil.move(str(lbl_src), str(lbl_to / lbl_src.name))\n",
    "\n",
    "def count_split(split: str):\n",
    "    img_n = len(list((DST / \"images\" / split).glob(\"*.*\")))\n",
    "    lbl_n = len(list((DST / \"labels\" / split).glob(\"*.txt\")))\n",
    "    return img_n, lbl_n\n",
    "\n",
    "def leak_check():\n",
    "    train = set(list_stems(DST / \"images\" / \"train\"))\n",
    "    val = set(list_stems(DST / \"images\" / \"val\"))\n",
    "    test = set(list_stems(DST / \"images\" / \"test\"))\n",
    "    return len(train & val), len(train & test), len(val & test)\n",
    "\n",
    "def main():\n",
    "    random.seed(SEED)\n",
    "    if DST.exists():\n",
    "        raise RuntimeError(f\"DST zaten var, sil veya ad değiştir: {DST}\")\n",
    "\n",
    "    copy_tree()\n",
    "\n",
    "    val_stems = list_stems(DST / \"images\" / \"val\")\n",
    "    test_stems = list_stems(DST / \"images\" / \"test\")\n",
    "\n",
    "    if len(val_stems) < TARGET_VAL:\n",
    "        raise ValueError(\"Val zaten hedefin altında.\")\n",
    "    if len(test_stems) < TARGET_TEST:\n",
    "        raise ValueError(\"Test zaten hedefin altında.\")\n",
    "\n",
    "    move_from_val = len(val_stems) - TARGET_VAL\n",
    "    move_from_test = len(test_stems) - TARGET_TEST\n",
    "\n",
    "    val_pick = random.sample(val_stems, move_from_val)\n",
    "    test_pick = random.sample(test_stems, move_from_test)\n",
    "\n",
    "    for stem in val_pick:\n",
    "        move_pair(stem, \"val\", \"train\")\n",
    "    for stem in test_pick:\n",
    "        move_pair(stem, \"test\", \"train\")\n",
    "\n",
    "    for split in [\"train\", \"val\", \"test\"]:\n",
    "        img_n, lbl_n = count_split(split)\n",
    "        print(f\"{split}: images={img_n} labels={lbl_n}\")\n",
    "\n",
    "    a, b, c = leak_check()\n",
    "    print(\"leak check train∩val:\", a)\n",
    "    print(\"leak check train∩test:\", b)\n",
    "    print(\"leak check val∩test:\", c)\n",
    "    print(\"Bitti:\", DST)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30b9778b",
   "metadata": {},
   "source": [
    "Beklenen çıktı (yaklaşık):\n",
    "\n",
    "* train: images=3355 labels=3355\n",
    "\n",
    "* val: images=350 labels=350\n",
    "\n",
    "* test: images=700 labels=700\n",
    "\n",
    "* leak check hepsi 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c978fe0",
   "metadata": {},
   "source": [
    "### Bu işlem tamamlandığında ilk çözümlenmiş veri setini projeden kaldırıyoruz. \n",
    "##### > **\"C:\\Users\\hdgn5\\OneDrive\\Masaüstü\\Head Detection\\scut_head_yolo\"**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ade2201",
   "metadata": {},
   "source": [
    "----\n",
    "----\n",
    "----\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b62def4",
   "metadata": {},
   "source": [
    "## Adım 4 — YOLO Veri Tanımlama Dosyası (`dataset.yaml`) Oluşturma\n",
    "\n",
    "Bu adımın amacı, hazırladığımız YOLO formatındaki veri setini Ultralytics YOLO eğitim pipeline’ına tanıtmaktır.  \n",
    "YOLO eğitim komutu, train/val/test görüntülerinin nerede bulunduğunu ve sınıf isimlerini `dataset.yaml` dosyasından okur.\n",
    "\n",
    "### 4.1 `dataset.yaml` dosyasının konumu\n",
    "\n",
    "`dataset.yaml` dosyası, veri setinin **kök dizinine** (yani `images/` ve `labels/` klasörleri ile aynı seviyeye) kaydedilmelidir:\n",
    "\n",
    "- `C:\\Users\\hdgn5\\OneDrive\\Masaüstü\\Head Detection\\scut_head_yolo_rebalanced\\dataset.yaml`\n",
    "\n",
    "Bu sayede YAML içindeki `train`, `val`, `test` yolları **göreli (relative)** yazılabilir ve taşınabilirlik artar.\n",
    "\n",
    "### 4.2 `dataset.yaml` dosya içeriği\n",
    "\n",
    "Aşağıdaki içerik, tek sınıflı (head) bir detection veri seti için yeterlidir:\n",
    "\n",
    "```yaml\n",
    "path: .\n",
    "train: images/train\n",
    "val: images/val\n",
    "test: images/test\n",
    "\n",
    "names:\n",
    "  0: head\n",
    "```\n",
    "**Bu adım tamamlandıktan sonra eğitim aşamasında data=dataset.yaml parametresi kullanılarak model fine-tuning sürecine geçilecektir.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f1115bf",
   "metadata": {},
   "source": [
    "----\n",
    "-----"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch_gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
